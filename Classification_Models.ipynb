{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'C:/Users/kseht/Desktop/UH Spring 2022/Advance NLP/Project/Train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "file_name = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    f= open(file, errors = \"ignore\")\n",
    "#     print(f.read())\n",
    "#     print('File name is : ', file)\n",
    "    text = f.read().replace('\\n', ' ')\n",
    "    text = text.replace('\\t',' ')\n",
    "    text = text.replace('   ', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('[', '')\n",
    "    text = text.replace(']', '')\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace(\"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\", '')\n",
    "    text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n",
    "    text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n",
    "    #removing numbers\n",
    "    text = re.sub('\\d+', '',text)\n",
    "    # removing the bullets\n",
    "    text = re.sub('[(\\s][0-9a-zA-Z][.)]\\s+|[(\\s][ivxIVX]+[.)]\\s+', ' ', text)\n",
    "    #removing all the URL from the text\n",
    "    text = re.sub('(www|http)\\S+', '',text)\n",
    "    # removing the special characters\n",
    "    text = re.sub('(å¼«¥ª°©ð±§µæ¹¢³¿®ä£)\\S+','', text)\n",
    "#     text = re.sub(\"[\\<103D-Legio-5M The Memorial Exami¹d\\>]+\", '', text) \n",
    "    text = re.sub(\"#\\w+\", '', text)\n",
    "#     text = re.sub(\"[.nf]\", '', text)\n",
    "    #extracting symbols and characters\n",
    "    text=re.sub(r'@\\w+',\"\",text)\n",
    "    text=re.sub(r'#\\w+',\"\",text) \n",
    "    text=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text) \n",
    "    punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
    "\n",
    "#     text=re.sub('[^A-Za-z\\s]+',\"\", text)\n",
    "#     text = text.lower()\n",
    "#     text = text.split()\n",
    "#     print(text)\n",
    "#     print('File name is : ', file)\n",
    "\n",
    "    # Removed the sentences having length less then 5\n",
    "    #sentences = [sent for sent in sentences if len(sent) >= 5]\n",
    "    #text_list.append(sentences)\n",
    "#     text=text.lower()\n",
    "    text_list.append(text)\n",
    "    file_name.append(file)\n",
    "\n",
    "# print(text_list)\n",
    "# print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'File Name' : file_name,\n",
    "       'Text' : text_list}\n",
    "train_df = pd.DataFrame(data1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv(r'C:/Users/kseht/Desktop/UH Spring 2022/Advance NLP/Project/Dataset/Defoe/Dataset/train_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv (r'C:/Users/kseht/Desktop/UH Spring 2022/Advance NLP/Project/Dataset/Defoe/Dataset/New_dataset.csv')\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger1 = [0,1,2,3,4,5]\n",
    "# tagger1 = ['Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tag'] = tagger1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'C:/Users/kseht/Desktop/UH Spring 2022/Advance NLP/Project/Dataset/Defoe/Defoe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "file_name = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    f= open(file, errors = \"ignore\")\n",
    "#     print(f.read())\n",
    "#     print('File name is : ', file)\n",
    "    text = f.read().replace('\\n', ' ')\n",
    "    text = text.replace('\\t',' ')\n",
    "    text = text.replace('   ', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('[', '')\n",
    "    text = text.replace(']', '')\n",
    "    text = text.replace('.nf', '')\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace(\"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\", '')\n",
    "    text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n",
    "    text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n",
    "    #removing numbers\n",
    "    text = re.sub('\\d+', '',text)\n",
    "    # removing the bullets\n",
    "    text = re.sub('[(\\s][0-9a-zA-Z][.)]\\s+|[(\\s][ivxIVX]+[.)]\\s+', ' ', text)\n",
    "    #removing all the URL from the text\n",
    "    text = re.sub('(www|http)\\S+', '',text)\n",
    "    # removing the special characters\n",
    "    text = re.sub('(å¼«¥ª°©ð±§µæ¹¢³¿®ä£)\\S+','', text)\n",
    "#     text = re.sub(\"[\\<103D-Legio-5M The Memorial Exami¹d\\>]+\", '', text) \n",
    "    text = re.sub(\"#\\w+\", '', text)\n",
    "#     text = re.sub(\"[.nf]\", '', text)\n",
    "    #extracting symbols and characters\n",
    "    text=re.sub(r'@\\w+',\"\",text)\n",
    "    text=re.sub(r'#\\w+',\"\",text) \n",
    "    text=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text) \n",
    "    punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
    "\n",
    "#     text=re.sub('[^A-Za-z\\s]+',\"\", text)\n",
    "#     text = text.lower()\n",
    "#     text = text.split()\n",
    "#     print(text)\n",
    "#     print('File name is : ', file)\n",
    "\n",
    "    # Removed the sentences having length less then 5\n",
    "    #sentences = [sent for sent in sentences if len(sent) >= 5]\n",
    "    #text_list.append(sentences)\n",
    "#     text=text.lower()\n",
    "    text_list.append(text)\n",
    "    file_name.append(file)\n",
    "\n",
    "# print(text_list)\n",
    "# print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {'File Name' : file_name,\n",
    "       'Text' : text_list}\n",
    "test_df = pd.DataFrame(data2)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagger2 = ['Daniel Defoe','Alexander Pope','Alfred Tennyson','Daniel Defoe','Percy Bysshe Shelley','Daniel Defoe','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Daniel Defoe','Daniel Defoe','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Daniel Defoe','Daniel Defoe','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Daniel Defoe','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning','Percy Bysshe Shelley','John Gay','Daniel Defoe','Alexander Pope','Alfred Tennyson','Elizabeth Barrett Browning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger2 = [0,1,2,3,4,5,0,1,2,3,4,5,0,1,2,3,4,5,0,1,0,0,0,0,0,0,0,0,0,0,0,2,3,4,5,0,1,2,3,4,5,0,1,2,3,0,0,0,0,1,2,1,4,5,0,1,2,3,4,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,2,3,4,5,0,1,2,3,0,0,0,0,0,0,0,0,4,5,0,1,2,3,4,5,0,1,2,3,4,5,0,1,2,3,4,5,0,1,0,0,0,0,0,2,3,4,5,0,1,2,3,4,5,0,1,2,3,4,5,0,3,4,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Tag'] = tagger2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = [test_df, train_df]\n",
    "ret = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret['Text'] = ret['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ret['Text'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "print(stop[::10])\n",
    "\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(description):\n",
    "    \"\"\"The function to remove punctuation\"\"\"\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return description.translate(table)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"The function to removing stopwords\"\"\"\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def stemmer(stem_text):\n",
    "    \"\"\"The function to apply stemming\"\"\"\n",
    "    stem_text = [porter.stem(word) for word in stem_text.split()]\n",
    "    return \" \".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret['Text'] = ret['Text'].apply(remove_punctuation)\n",
    "ret['Text'] = ret['Text'].apply(remove_stopwords)\n",
    "ret['Text'] = ret['Text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(ret['Text'])\n",
    "vector = vectorizer.transform(ret['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the tfid representation matrix of the text data\n",
    "tfidf_converter = TfidfTransformer()\n",
    "X_tfidf = tfidf_converter.fit_transform(vector).toarray()\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ret['Text']\n",
    "y = ret['Tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('model',LogisticRegression()),\n",
    "                     ])\n",
    "\n",
    "model_log.fit(X_train, y_train)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "pred = model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(pred, y_test))\n",
    "print(classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = Pipeline([('vect', CountVectorizer(min_df=4, ngram_range=(1,5))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model',LinearSVC()),\n",
    "               ])\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model',MultinomialNB()),\n",
    "               ])\n",
    "\n",
    "nbc.fit(X_train, y_train)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "pred_y = nbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(pred_y, y_test))\n",
    "# print(classification_report(ytest, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('rf', RandomForestClassifier(n_estimators=50)),\n",
    "               ])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(preds, y_test))\n",
    "print(classification_report(ytest, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
